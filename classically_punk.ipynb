{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import asyncio\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Set a path to audiofiles and check if they are being accessed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"genres\"\n",
    "genres = glob(path + \"/*\")\n",
    "audio_files = glob(path + \"/**/*.wav\", recursive=True)\n",
    "\n",
    "#Checking that audiofiles and genres paths have been identified correctly\n",
    "genres_list = [os.path.basename(genre_path) for genre_path in genres if \".mf\" not in genre_path]\n",
    "audio_files_list = [os.path.basename(file) for file in audio_files if \".mf\" not in audio_files]\n",
    "print(genres_list)\n",
    "print(audio_files_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create a function to extract features from audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_features(y, sr):\n",
    "    #y, sr = librosa.load(file, sr=None, duration=seconds) # Load audio for specified duration\n",
    "\n",
    "    # Extracting features from audio\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    harmony, perceptr = librosa.effects.hpss(y)\n",
    "    tempo = librosa.beat.tempo(y=y, sr=sr)\n",
    "    length = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    # Aggregate features\n",
    "    features = {\n",
    "        \"name\": os.path.basename(file).split(\".wav\")[0].replace(\".\", \"_\"),\n",
    "        \"genre\": os.path.basename(file).split(\".\")[0],\n",
    "        \"length\": length,\n",
    "        \"tempo\": tempo,\n",
    "        **{f\"mfcc{i+1}_mean\": np.mean(mfcc[i]) for i in range(13)},\n",
    "        **{f\"mfcc{i+1}_var\": np.var(mfcc[i]) for i in range(13)},\n",
    "        \"chroma_stft_mean\": np.mean(chroma_stft),\n",
    "        \"chroma_stft_var\": np.var(chroma_stft),\n",
    "        \"spectral_centroid_mean\": np.mean(spectral_centroid),\n",
    "        \"spectral_centroid_var\": np.var(spectral_centroid),\n",
    "        \"spectral_bandwidth_mean\": np.mean(spectral_bandwidth),\n",
    "        \"spectral_bandwidth_var\": np.var(spectral_bandwidth),\n",
    "        \"rolloff_mean\": np.mean(rolloff),\n",
    "        \"rolloff_var\": np.var(rolloff),\n",
    "        \"zero_crossing_rate_mean\": np.mean(zero_crossing_rate),\n",
    "        \"zero_crossing_rate_var\": np.var(zero_crossing_rate),\n",
    "        \"rms_mean\": np.mean(rms),\n",
    "        \"rms_var\": np.var(rms),\n",
    "        \"mel_mean\": np.mean(mel),\n",
    "        \"mel_var\": np.var(mel),\n",
    "        \"contrast_mean\": np.mean(contrast),\n",
    "        \"contrast_var\": np.var(contrast),\n",
    "        \"tonnetz_mean\": np.mean(tonnetz),\n",
    "        \"tonnetz_var\": np.var(tonnetz),\n",
    "        \"harmony_mean\": np.mean(harmony),\n",
    "        \"harmony_var\": np.var(harmony),\n",
    "        \"perceptr_mean\": np.mean(perceptr),\n",
    "        \"perceptr_var\": np.var(perceptr)\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Iterate over files and folders. and extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO REVIEWER: Features are already extracted in csv files. You can skip this step, as it's going to take a while to regenerate the dataset.\n",
    "\n",
    "num_segments = 10 #Segments - how many parts are we splitting the audio into\n",
    "\n",
    "feature_list_3 = [] #features spilt in 10 segments \n",
    "feature_list_30 = [] #features of full audiofile\n",
    " \n",
    "for file in audio_files:\n",
    "    print(\"processing\", file)\n",
    "    y, sr = librosa.load(file, sr=None) \n",
    "    samples_per_segment = len(y) // num_segments  #Calculate samples per segment\n",
    "    feature_list_30.append(await extract_features(y, sr))\n",
    "    for segment in range(num_segments):\n",
    "        start_sample = segment * samples_per_segment  #Start sample index of each segment\n",
    "        end_sample = (segment + 1) * samples_per_segment  #End sample index of each segment\n",
    "        segment_features = await extract_features(y[start_sample:end_sample], sr)\n",
    "        feature_list_3.append(segment_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_3\n",
    "feature_list_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Save the extracted features to a respective CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_3 = pd.DataFrame(feature_list_3)\n",
    "df_features_3.to_csv(\"extracted_features_3sec.csv\", index=False)\n",
    "\n",
    "df_features_30 = pd.DataFrame(feature_list_30)\n",
    "df_features_30.to_csv(\"extracted_features_30sec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Create, run and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3sec = pd.read_csv(\"extracted_features_3sec.csv\")\n",
    "df_30sec = pd.read_csv(\"extracted_features_30sec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode \"genre\" column\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_3sec[\"genre\"] = label_encoder.fit_transform(df_3sec[\"genre\"])\n",
    "print(df_3sec[\"genre\"])\n",
    "\n",
    "df_30sec[\"genre\"] = label_encoder.transform(df_30sec[\"genre\"])\n",
    "print(df_30sec[\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_combined = pd.concat([df_3sec, df_30sec], ignore_index=True)\n",
    "\n",
    "#Split features and labels\n",
    "X = df_combined.drop(columns=['name', 'genre', 'length'])\n",
    "y = df_combined['genre'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"), \n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"), \n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"), \n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(len(label_encoder.classes_), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=120, batch_size=128, validation_split=0.3)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "#Generate report\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
